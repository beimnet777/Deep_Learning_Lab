{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOgXRz1aEPAd"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DenseLayer:\n",
        "\n",
        "    def __init__(self,n_features, n_neurons):\n",
        "        self.weights = torch.rand((n_features,n_neurons))\n",
        "        self.bias = torch.rand(n_neurons)\n",
        "\n",
        "    def forward(self,inputs):\n",
        "        self.output = torch.matmul(inputs,self.weights) + self.bias"
      ],
      "metadata": {
        "id": "nZ_4kgyCEpDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Accuracy:\n",
        "\n",
        "    def forward(self,y_pred,y_true):\n",
        "        if y_pred.shape != y_true.shape:\n",
        "            one_hot_notation = torch.zeros(y_pred.shape)\n",
        "            one_hot_notation[range(len(y_pred)),y_true] = 1\n",
        "        else:\n",
        "            one_hot_notation = y_true\n",
        "        correct_values = y_pred==one_hot_notation\n",
        "        correct_values = correct_values * one_hot_notation\n",
        "        self.output = torch.sum(correct_values) / len(y_pred)\n",
        "        return self.output"
      ],
      "metadata": {
        "id": "MPOlcKkzFOLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(inputs):\n",
        "    output = 1 / (1 + torch.exp(inputs*-1))\n",
        "    return output\n",
        "\n",
        "def relu(inputs):\n",
        "    output = torch.max(inputs,torch.tensor(0))\n",
        "    return output"
      ],
      "metadata": {
        "id": "OOpAI85oFcf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassificationModel:\n",
        "    def __init__(self,num_of_features:int,num_of_classes:int):\n",
        "        self.dense_layer = DenseLayer(num_of_features,4)\n",
        "        self.output_layer = DenseLayer(4,num_of_classes)\n",
        "        self.accuracy = Accuracy()\n",
        "        self.errors = [float('inf')] * num_of_classes\n",
        "\n",
        "    def forward_propagate(self,inputs):\n",
        "        self.dense_layer.forward(inputs)\n",
        "        self.activation1 = relu(self.dense_layer.output)\n",
        "        self.output_layer.forward(self.activation1)\n",
        "        self.activation2 = sigmoid(self.output_layer.output)\n",
        "        self.inputs = inputs\n",
        "\n",
        "    def loss_and_accuracy(self,output):\n",
        "        self.true_value = output\n",
        "        if self.activation2.shape != output.shape:\n",
        "            one_hot_notation = torch.zeros(self.activation2.shape)\n",
        "            one_hot_notation[range(len(self.activation2)),output] = 1\n",
        "            self.true_value = one_hot_notation\n",
        "\n",
        "        loss = ((self.true_value - self.output_layer.output) ** 2) / 2\n",
        "        loss = torch.mean(loss)\n",
        "        accuracy = self.accuracy.forward(self.output_layer.output,self.true_value)\n",
        "        return loss, accuracy\n",
        "\n",
        "\n",
        "    def back_prop(self,lr):\n",
        "        errors = -(self.true_value - self.output_layer.output) # d(y-output)/d(output)\n",
        "        avg_errors = torch.sum(errors,keepdims=True,dim=0) / len(errors)\n",
        "        avg_errors = torch.squeeze(avg_errors)\n",
        "        avg_outputs = torch.sum(self.activation2,keepdims=True,dim=0) / len(self.activation2)\n",
        "        avg_outputs = torch.squeeze(avg_outputs)\n",
        "        avg_act1_outputs = torch.sum(self.activation1,keepdims=True,dim=0) / len(self.activation1)\n",
        "        avg_act1_outputs = torch.squeeze(avg_act1_outputs)\n",
        "        avg_inputs = torch.sum(self.inputs,keepdims=True,dim=0) / len(self.inputs)\n",
        "        avg_inputs = torch.squeeze(avg_inputs)\n",
        "        avg_layer1_output = torch.sum(self.dense_layer.output,keepdims=True,dim=0) / len(self.dense_layer.output)\n",
        "        avg_layer1_output = torch.squeeze(avg_layer1_output)\n",
        "        back = [None] * 4\n",
        "        for j in range(4):\n",
        "            back[j] = torch.tensor(lr) * avg_errors[j] * (avg_outputs[j] * (1-avg_outputs[j]))\n",
        "\n",
        "        for i in range(4):\n",
        "            self.output_layer.bias[i] -= back[i]\n",
        "            for j in range(4):\n",
        "                self.output_layer.weights[i][j] -= back[j] * avg_act1_outputs[i]\n",
        "\n",
        "\n",
        "        for j in range(4):\n",
        "            for k in range(4):\n",
        "                self.dense_layer.bias[j] -= back[j] * self.output_layer.weights[j][k] * (1 if avg_layer1_output[j]>0 else 0)\n",
        "                for i in range(2):\n",
        "                    self.dense_layer.weights[i][j] -= back[k] * self.output_layer.weights[j][k] * avg_inputs[i] * (1 if avg_layer1_output[j]>0 else 0)\n"
      ],
      "metadata": {
        "id": "060PytYAF0XJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ClassificationModel(2,4)\n",
        "x = torch.tensor([[1,2],[3,4],[4,5]],dtype=torch.float)\n",
        "y = torch.tensor([1,1,0])\n",
        "model.forward_propagate(x)\n",
        "model.loss_and_accuracy(y)\n",
        "\n",
        "loss = 0.1\n",
        "error = float('inf')\n",
        "iterations = 0\n",
        "while loss < error:\n",
        "    iterations += 1\n",
        "    model.forward_propagate(x)\n",
        "    model.back_prop(0.01)\n",
        "    error,acc = model.loss_and_accuracy(y)\n",
        "\n",
        "print(\"iterations:\",iterations)\n",
        "print(\"final output:\",model.output_layer.output)\n",
        "print(\"true vaues:\",model.true_value)\n",
        "print(\"accuracy:\",acc)\n",
        "print(\"final error:\",error)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6B4TJxaW91a",
        "outputId": "4578dd2f-8067-4112-8c35-839d95e2668d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iterations: 216\n",
            "final output: tensor([[ 0.8000,  0.6778,  0.1026,  0.6405],\n",
            "        [ 0.4846,  0.5030, -0.0199,  0.3375],\n",
            "        [ 0.4747,  0.5022, -0.0139,  0.3313]])\n",
            "true vaues: tensor([[0., 1., 0., 0.],\n",
            "        [0., 1., 0., 0.],\n",
            "        [1., 0., 0., 0.]])\n",
            "accuracy: tensor(0.)\n",
            "final error: tensor(0.0999)\n"
          ]
        }
      ]
    }
  ]
}