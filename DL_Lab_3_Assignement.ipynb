{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "00VMF-hTaZ0q"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DenseLayer:\n",
        "    def __init__(self, n_features, n_neurons, activation_function):\n",
        "        self.weights = torch.rand((n_features, n_neurons), requires_grad=True)\n",
        "        self.biases = torch.zeros((1, n_neurons), requires_grad=True)\n",
        "        self.activation_function = activation_function\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        weighted_sum = torch.matmul(inputs, self.weights) + self.biases\n",
        "        self.output = self.activation_function(weighted_sum)"
      ],
      "metadata": {
        "id": "vkrXlflUcTH9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def activation_relu(inputs):\n",
        "    return torch.maximum(torch.zeros_like(inputs), inputs)\n",
        "\n",
        "def activation_softmax(inputs):\n",
        "    exp_values = torch.exp(inputs - torch.max(inputs, dim=1, keepdim=True).values)\n",
        "    return exp_values / torch.sum(exp_values, dim=1, keepdim=True)\n",
        "\n",
        "def activation_sigmoid(inputs):\n",
        "    return 1 / (1 + torch.exp(-inputs))"
      ],
      "metadata": {
        "id": "XH4jZtAIbrnX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def categorical_crossentropy(y_pred, y_true):\n",
        "    y_pred_clipped = torch.clamp(y_pred, 1e-7, 1 - 1e-7)\n",
        "    log_likelihoods = -torch.sum(y_true * torch.log(y_pred_clipped))\n",
        "    return log_likelihoods\n"
      ],
      "metadata": {
        "id": "Rw6emzhrdVR8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Net with relu activation function"
      ],
      "metadata": {
        "id": "N9A3aP7ndwPu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_section_relu():\n",
        "    torch.manual_seed(30)\n",
        "    input_data = torch.rand((1, 4), requires_grad=True)\n",
        "\n",
        "    # 3 hidden layers\n",
        "    layer1 = DenseLayer(4, 18, activation_relu)\n",
        "    layer2 = DenseLayer(18, 18, activation_relu)\n",
        "    layer3 = DenseLayer(18, 18, activation_relu)\n",
        "    # output layer\n",
        "    output_layer = DenseLayer(18, 3, activation_softmax)\n",
        "\n",
        "    # Forward pass\n",
        "    layer1.forward(input_data)\n",
        "    layer2.forward(layer1.output)\n",
        "    layer3.forward(layer2.output)\n",
        "    output_layer.forward(layer3.output)\n",
        "\n",
        "    target = torch.tensor([0, 1, 0], dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "    # Computing loss\n",
        "    loss = categorical_crossentropy(output_layer.output, target)\n",
        "    accuracy = target == torch.argmax(output_layer.output, dim=1)\n",
        "\n",
        "    print(\"Using ReLU for hidden layers:\")\n",
        "    print(\"Final output:\", output_layer.output)\n",
        "    print(\"Categorical Cross-Entropy Loss:\", loss.item())\n",
        "    print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "QulwQqegd0q0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_section_relu()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mi6wzoXCsFxp",
        "outputId": "6f34c0c2-2e7c-4520-899d-8d34680cd56f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using ReLU for hidden layers:\n",
            "Final output: tensor([[1., 0., 0.]], grad_fn=<DivBackward0>)\n",
            "Categorical Cross-Entropy Loss: 16.11809539794922\n",
            "Accuracy: tensor([ True, False,  True])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Neural Net with relu activation function"
      ],
      "metadata": {
        "id": "sbEEnSEAeBL2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_section_sigmoid():\n",
        "    torch.manual_seed(30)\n",
        "    input_data = torch.rand((1, 4), requires_grad=True)\n",
        "\n",
        "    # 3 hidden layers\n",
        "    layer1 = DenseLayer(4, 18, activation_sigmoid)\n",
        "    layer2 = DenseLayer(18, 18, activation_sigmoid)\n",
        "    layer3 = DenseLayer(18, 18, activation_sigmoid)\n",
        "    # output layer\n",
        "    output_layer = DenseLayer(18, 3, activation_softmax)\n",
        "\n",
        "    # Forward pass\n",
        "    layer1.forward(input_data)\n",
        "    layer2.forward(layer1.output)\n",
        "    layer3.forward(layer2.output)\n",
        "    output_layer.forward(layer3.output)\n",
        "\n",
        "    target = torch.tensor([0, 1, 0], dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "    # Computing loss\n",
        "    loss = categorical_crossentropy(output_layer.output, target)\n",
        "    accuracy = target == torch.argmax(output_layer.output, dim=1)\n",
        "\n",
        "    print(\"Using Sigmoid for hidden layers:\")\n",
        "    print(\"Final output:\", output_layer.output)\n",
        "    print(\"Categorical Cross-Entropy Loss:\", loss.item())\n",
        "    print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "0D-VuiQ6eHns"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_section_sigmoid()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Cw73tyveOq9",
        "outputId": "bfeae7dd-51e5-4806-c788-b2e8f57b6cea"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Sigmoid for hidden layers:\n",
            "Final output: tensor([[0.7504, 0.1407, 0.1089]], grad_fn=<DivBackward0>)\n",
            "Categorical Cross-Entropy Loss: 1.961198329925537\n",
            "Accuracy: tensor([ True, False,  True])\n"
          ]
        }
      ]
    }
  ]
}